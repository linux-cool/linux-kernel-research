# 记忆推理系统配置文件

# 系统基本配置
system:
  name: "Memory Reasoning System"
  version: "1.0.0"
  environment: "development"  # development, staging, production
  debug: true
  log_level: "INFO"

# 服务器配置
server:
  host: "0.0.0.0"
  port: 8080
  workers: 4
  timeout: 30
  max_connections: 1000

# 数据库配置
database:
  # 主数据库 (PostgreSQL)
  primary:
    type: "postgresql"
    host: "localhost"
    port: 5432
    database: "memory_reasoning_db"
    username: "memory_user"
    password: "memory_password"
    pool_size: 10
    max_overflow: 20
    pool_timeout: 30
    pool_recycle: 3600

  # Redis缓存
  redis:
    host: "localhost"
    port: 6379
    database: 0
    password: null
    max_connections: 50
    socket_timeout: 5
    socket_connect_timeout: 5

# 向量数据库配置
vector_database:
  # Chroma配置
  chroma:
    host: "localhost"
    port: 8000
    collection_name: "memory_embeddings"
    distance_metric: "cosine"
    
  # Pinecone配置 (可选)
  pinecone:
    api_key: "${PINECONE_API_KEY}"
    environment: "us-west1-gcp"
    index_name: "memory-index"
    dimension: 1536

  # FAISS配置 (本地)
  faiss:
    index_path: "./data/faiss_index"
    dimension: 1536
    index_type: "IVF"
    nlist: 100

# 嵌入模型配置
embeddings:
  # OpenAI嵌入
  openai:
    api_key: "${OPENAI_API_KEY}"
    model: "text-embedding-ada-002"
    max_tokens: 8191
    batch_size: 100

  # 本地嵌入模型
  local:
    model_name: "sentence-transformers/all-MiniLM-L6-v2"
    device: "cpu"  # cpu, cuda
    batch_size: 32

# 大语言模型配置
llm:
  # OpenAI GPT
  openai:
    api_key: "${OPENAI_API_KEY}"
    model: "gpt-4"
    temperature: 0.7
    max_tokens: 2048
    top_p: 1.0
    frequency_penalty: 0.0
    presence_penalty: 0.0

  # Anthropic Claude
  anthropic:
    api_key: "${ANTHROPIC_API_KEY}"
    model: "claude-3-sonnet-20240229"
    temperature: 0.7
    max_tokens: 2048

  # 本地模型 (Ollama)
  local:
    base_url: "http://localhost:11434"
    model: "llama2"
    temperature: 0.7
    max_tokens: 2048

# 记忆系统配置
memory:
  # 短期记忆
  short_term:
    max_size: 1000
    ttl: 3600  # 1小时
    cleanup_interval: 300  # 5分钟

  # 长期记忆
  long_term:
    max_size: 100000
    compression_threshold: 0.8
    similarity_threshold: 0.85
    auto_cleanup: true
    cleanup_interval: 86400  # 24小时

  # 工作记忆
  working:
    max_size: 50
    context_window: 4096
    attention_mechanism: "multi_head"

# 推理引擎配置
reasoning:
  # 逻辑推理
  logical:
    max_depth: 10
    timeout: 30
    use_cache: true
    cache_ttl: 1800

  # 类比推理
  analogical:
    similarity_threshold: 0.7
    max_analogies: 5
    weight_structure: 0.6
    weight_semantic: 0.4

  # 因果推理
  causal:
    confidence_threshold: 0.8
    max_chain_length: 5
    temporal_window: 86400  # 24小时

# 知识图谱配置
knowledge_graph:
  # Neo4j配置
  neo4j:
    uri: "bolt://localhost:7687"
    username: "neo4j"
    password: "neo4j_password"
    database: "memory_kg"
    max_connection_lifetime: 3600
    max_connection_pool_size: 50

  # 实体识别
  entity_recognition:
    model: "spacy"
    language: "zh_core_web_sm"
    confidence_threshold: 0.8

  # 关系抽取
  relation_extraction:
    model: "custom"
    confidence_threshold: 0.7
    max_relations_per_text: 10

# 安全配置
security:
  # API密钥管理
  api_keys:
    enabled: true
    key_length: 32
    expiry_days: 90

  # 访问控制
  access_control:
    rate_limit:
      requests_per_minute: 100
      burst_size: 20
    
    ip_whitelist: []
    ip_blacklist: []

  # 数据加密
  encryption:
    algorithm: "AES-256-GCM"
    key_rotation_days: 30
    encrypt_at_rest: true

# 监控配置
monitoring:
  # Prometheus指标
  prometheus:
    enabled: true
    port: 9090
    path: "/metrics"

  # 日志配置
  logging:
    level: "INFO"
    format: "json"
    file: "./logs/memory_reasoning.log"
    max_size: "100MB"
    backup_count: 5
    rotation: "daily"

  # 健康检查
  health_check:
    enabled: true
    interval: 30
    timeout: 10
    endpoints:
      - "/health"
      - "/ready"

# 性能优化配置
performance:
  # 缓存配置
  cache:
    enabled: true
    ttl: 3600
    max_size: 10000
    eviction_policy: "LRU"

  # 批处理
  batch_processing:
    enabled: true
    batch_size: 100
    max_wait_time: 5
    max_batch_size: 1000

  # 并发控制
  concurrency:
    max_workers: 10
    queue_size: 1000
    timeout: 60

# 数据管道配置
data_pipeline:
  # 数据摄取
  ingestion:
    batch_size: 1000
    max_file_size: "100MB"
    supported_formats: ["txt", "pdf", "docx", "json", "csv"]
    
  # 数据预处理
  preprocessing:
    text_cleaning: true
    language_detection: true
    chunking:
      strategy: "semantic"
      chunk_size: 1000
      overlap: 200

  # 数据验证
  validation:
    schema_validation: true
    content_validation: true
    duplicate_detection: true

# 实验配置
experiments:
  # A/B测试
  ab_testing:
    enabled: false
    default_variant: "control"
    traffic_split: 0.5

  # 特征标志
  feature_flags:
    new_reasoning_engine: false
    enhanced_memory_compression: true
    experimental_embeddings: false

# 备份和恢复
backup:
  enabled: true
  schedule: "0 2 * * *"  # 每天凌晨2点
  retention_days: 30
  storage:
    type: "local"  # local, s3, gcs
    path: "./backups"
    
  # S3配置 (如果使用)
  s3:
    bucket: "memory-reasoning-backups"
    region: "us-west-2"
    access_key: "${AWS_ACCESS_KEY_ID}"
    secret_key: "${AWS_SECRET_ACCESS_KEY}"
